---
title: "Related Work"
---

## Related Work

Intrusion detection systems (IDS) for in-vehicle CAN networks can be classified by detection scope, data type, and underlying detection paradigm. We organize prior work along these dimensions to highlight the unique contributions of our approach.

### CAN IDS by Detection Scope

**Packet-Based Approaches.** Packet-based IDSs analyze individual CAN frames for fast, lightweight detection, but cannot capture dependencies across messages, limiting effectiveness against sophisticated attacks such as spoofing or replay. For example, @Kang applied deep neural networks to individual CAN messages using simulated data, and @Groza exploited traffic periodicity using Bloom filters. However, these methods are ineffective for aperiodic frames [@Cheng], which are common in real-world CAN buses.

**Window-Based Approaches.** Window-based IDSs analyze sequences of CAN frames, enabling better temporal correlation analysis. @Olufowobi developed timing models for real-time detection without relying on protocol specifications, but still struggled with aperiodic messages and repeated CAN IDs. Frequency and Hamming distance-based methods [@Taylor] are similarly limited against aperiodic attacks [@Bozdal; @Choi]. @Islam combined graph features with statistical tests for anomaly and replay detection, but at the cost of increased latency due to requiring larger message batches.

**Graph-Based Approaches.** Graph-based IDSs better capture ECU communication patterns by modeling message relationships, but often target only simple attacks. @GIDCS proposed G-IDCS, which combines an interpretable threshold-based stage with a learnable classifier leveraging message correlation, enabling detection of more complex attacks than packet-based methods. However, these approaches typically use static detection rules and do not adaptively combine multiple expert models.

### Deep Learning and Ensemble Methods

Most recent CAN IDS approaches are anomaly-based, learning normal behavior and flagging deviations. @CNNLSTM proposed a CNN-LSTM-attention hybrid achieving over 98% accuracy by capturing both local and temporal patterns. Graph neural network approaches, such as GIDS [@GIDS], exploit graph convolutional networks (GCNs) to model message relationships, improving detection of structural and contextual anomalies. @CANADS showed that robust feature engineering and data balancing significantly enhance supervised ML-based IDS, achieving up to 97.7% accuracy.

Ensemble methods for automotive IDS typically employ homogeneous models or sequential fusion. For example, the Basic Ensemble and Pioneer Class Decision (BEPCD) framework [@BEPCD] uses an ensemble of tree-based models (XGBoost, Random Forest) with adaptive voting. Similarly, HyDL-IDS [@HyDL] sequentially fuses CNN and LSTM modules to capture spatiotemporal features, but operates as a single fixed pipeline rather than a dynamic multi-expert system. Recently, KD-GAT [@frenken2025kdgat] combined GAT with knowledge distillation to achieve a lightweight yet effective IDS. However, the student model closely matches the teacher in accuracy and, like other methods, still struggles with severe class imbalance.

### Multi-Modal and Cross-Domain Approaches

In broader cyber-physical systems (CPS) contexts, frameworks such as DGI-RBM [@DGIRBM] and GDN [@GDN] integrate physical features with GNNs for SCADA systems. However, these approaches rely on feature-level fusion, concatenating physical statistics directly into node embeddings. This static integration is brittle when modalities are missing or corrupted. Multi-view causal inference approaches [@MultiViewCausal] validate the multi-view fusion concept, but lack adaptive, reinforcement learning-based weighting strategies.

### Positioning Our Contribution

The key innovation distinguishing our work is *adaptive decision-level fusion via reinforcement learning*. Rather than static fusion strategies (voting, concatenation, or fixed weighting), we treat VGAE and GAT as independent experts with complementary strengths and use a DQN policy to learn sample-specific weights that adaptively select the most informative representation for each message context. This enables graceful degradation when one expert is unreliable and provides interpretability through learned weighting patterns.

Additionally, our hardware-aware knowledge distillation pipeline is principally scaled to automotive constraints (ARM Cortex-A7/A53, 256--512 MB RAM, 100 mW power budget), curriculum learning for class imbalance directly addresses the severe data imbalance (up to 927:1 ratios), and multi-dataset evaluation across six publicly available benchmarks demonstrates strong generalization and transferability.

| Framework | Domain | Model | Fusion | Limitation |
|-----------|--------|-------|--------|------------|
| BEPCD [@BEPCD] | Auto | RF, XGB | Vote | Classical ML only |
| HyDL [@HyDL] | Auto | CNN-LSTM | Seq. pipeline | Fixed pipeline |
| G-IDCS [@GIDCS] | Auto | GNN | Static rules | No fusion |
| KD-GAT [@frenken2025kdgat] | Auto | GAT | KD | Limited imbalance |
| DGI-RBM [@DGIRBM] | CPS | Phys.+GNN | Feature concat | Static fusion |
| GDN [@GDN] | CPS | GAT | None | Single model |
| **Proposed** | Auto | GAT+VGAE | DQN | Adaptive RL |

: Comparison of anomaly detection frameworks for automotive and CPS systems. Our approach uniquely combines heterogeneous experts (structural and distributional) with dynamic DQN-based adaptive fusion. {#tbl-comparison}
