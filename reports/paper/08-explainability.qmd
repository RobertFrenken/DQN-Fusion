---
title: "Explainability"
---

## Explainability

### UMAP Analysis

To understand the representations learned by our model, we perform UMAP-based feature analysis using both raw input statistics and learned graph embeddings. We sample 10% of graphs from the HCRL Car-Hacking dataset.

Raw CAN-graph data projected via UMAP shows loose clustering that indicates limited separability between normal and attack types. In contrast, UMAP projections of graph-level embeddings from the trained GAT classifier's penultimate layer reveal well-separated clusters.

Despite binary supervision (attack vs. normal), the learned embedding space forms well-separated clusters aligned with specific attack types (DoS, Fuzzy, Gear, RPM). This emergent multi-class structure demonstrates that our model captures high-level semantic patterns in CAN traffic and generalizes across attack categories without explicit multi-class labels. The clear cluster separation in embedding space, absent in raw features, validates the GAT's ability to learn discriminative representations from graph-structured temporal data.

### Composite VGAE Reconstruction Error

To assess the overall reconstruction quality of the VGAE, we combine three types of reconstruction errors: node feature reconstruction error ($E_{\text{node}}$), CAN ID prediction error ($E_{\text{CAN\,ID}}$), and neighborhood reconstruction error ($E_{\text{neighbor}}$). Each error captures a different aspect of the graph structure and message semantics. We compute a single composite score as a weighted sum:

$$
\mathrm{Composite\_Error} = \alpha\, E_{\text{node}} + \beta\, E_{\text{neighbor}} + \gamma\, E_{\text{CAN\,ID}}
$$ {#eq-composite-error}

where $\alpha$, $\beta$, and $\gamma$ are empirically chosen weights that regulate each term's influence. In our experiments, we use $\alpha = 1.0$, $\beta = 20.0$, and $\gamma = 0.3$.

This approach enables the detection of subtle anomalies by jointly evaluating node content, CAN identifier semantics, and local neighborhood structure.

### DQN-Fusion Analysis

The learned DQN fusion policy exhibits interpretable, context-specific weighting that validates adaptive expert selection. Analysis reveals a strong correlation between VGAE anomaly scores and fusion weights: low VGAE scores cluster at $\alpha \approx 0$ (favoring the robust expert), while higher scores transition to intermediate weights, demonstrating the policy learned to default to VGAE's out-of-distribution detection while conditionally leveraging GAT's strength on known attacks. The multimodal distribution with peaks at $\alpha \approx 0, 0.2, 0.4, 0.6, 0.8$ indicates the DQN discovered distinct attack-type-specific strategies rather than learning fixed averaging ($\alpha = 0.5$). Critically, the divergence between normal and attack distributions validates meaningful anomaly detection logic.
