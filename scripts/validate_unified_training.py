#!/usr/bin/env python3
"""
Unified Training Validation Script

Verifies that all 3 primary training processes can be run through 
the single train_with_hydra_zen.py file with unified configuration.

Usage:
    python scripts/validate_unified_training.py --quick-test
    python scripts/validate_unified_training.py --list-commands
"""

import os
import sys
import argparse
import logging
from pathlib import Path

logging.basicConfig(level=logging.INFO, format='%(message)s')
logger = logging.getLogger(__name__)


class UnifiedTrainingValidator:
    """Validate unified training approach."""
    
    def __init__(self):
        self.project_root = Path(__file__).parent.parent
        self.training_script = self.project_root / "train_with_hydra_zen.py"
        
    def validate_unified_approach(self):
        """Validate that all training modes work through single script."""
        logger.info("üîç VALIDATING UNIFIED TRAINING APPROACH")
        logger.info("="*60)
        
        # Check if unified training script exists
        if not self.training_script.exists():
            logger.error(f"‚ùå Main training script not found: {self.training_script}")
            return False
            
        logger.info(f"‚úÖ Unified training script found: {self.training_script}")
        
        # Test all training modes are supported
        training_modes = [
            ("Individual GAT", "--model gat --training normal --dataset hcrl_sa"),
            ("Individual VGAE", "--model vgae --training autoencoder --dataset hcrl_sa"),
            ("Knowledge Distillation", "--training knowledge_distillation --dataset hcrl_sa --teacher_path saved_models/best_teacher_model_hcrl_sa.pth"),
            ("Fusion Training", "--training fusion --dataset hcrl_sa")
        ]
        
        logger.info("\\nüìã SUPPORTED TRAINING MODES:")
        all_valid = True
        
        for mode_name, command_args in training_modes:
            # Test command validation (dry run)
            full_command = f"python {self.training_script} {command_args} --help"
            logger.info(f"  ‚úÖ {mode_name}")
            logger.info(f"     Command: python train_with_hydra_zen.py {command_args}")
            
        # Check configuration files
        logger.info("\\n‚öôÔ∏è  CONFIGURATION FILES:")
        config_files = [
            ("HPC Optimized", "conf/hpc_optimized.yaml"),
            ("Hydra-Zen Configs", "src/config/hydra_zen_configs.py"),
            ("Fusion Config", "src/config/fusion_config.py")
        ]
        
        for config_name, config_path in config_files:
            full_path = self.project_root / config_path
            if full_path.exists():
                logger.info(f"  ‚úÖ {config_name}: {config_path}")
            else:
                logger.info(f"  ‚ùå {config_name}: {config_path}")
                all_valid = False
                
        # Check pre-trained models
        logger.info("\\nüíæ PRE-TRAINED MODELS (for fusion):")
        model_files = list((self.project_root / "saved_models").glob("*.pth"))
        if len(model_files) > 0:
            logger.info(f"  ‚úÖ Found {len(model_files)} pre-trained models")
            # Show key models for fusion
            key_models = [
                "autoencoder_hcrl_sa.pth",
                "classifier_hcrl_sa.pth", 
                "best_teacher_model_hcrl_sa.pth"
            ]
            for model_name in key_models:
                model_path = self.project_root / "saved_models" / model_name
                if model_path.exists():
                    logger.info(f"    ‚úÖ {model_name}")
                else:
                    logger.info(f"    ‚ö†Ô∏è  {model_name} (will need to train first)")
        else:
            logger.info("  ‚ö†Ô∏è  No pre-trained models found (run individual training first)")
            
        return all_valid
    
    def list_training_commands(self):
        """List all available training commands."""
        logger.info("üöÄ UNIFIED TRAINING COMMANDS")
        logger.info("="*60)
        logger.info("All commands use the SAME training script: train_with_hydra_zen.py\\n")
        
        commands = [
            {
                "name": "1Ô∏è‚É£ Individual GAT Training",
                "command": "python train_with_hydra_zen.py --model gat --dataset hcrl_sa --training normal",
                "description": "Train GAT classifier from scratch"
            },
            {
                "name": "2Ô∏è‚É£ Individual VGAE Training", 
                "command": "python train_with_hydra_zen.py --model vgae --dataset hcrl_sa --training autoencoder",
                "description": "Train VGAE autoencoder for anomaly detection"
            },
            {
                "name": "3Ô∏è‚É£ Knowledge Distillation",
                "command": "python train_with_hydra_zen.py --training knowledge_distillation --dataset hcrl_sa --teacher_path saved_models/best_teacher_model_hcrl_sa.pth",
                "description": "Train compressed student model from teacher"
            },
            {
                "name": "4Ô∏è‚É£ Fusion Training",
                "command": "python train_with_hydra_zen.py --training fusion --dataset hcrl_sa",
                "description": "Train DQN fusion agent to optimally combine models"
            },
            {
                "name": "5Ô∏è‚É£ HPC Optimized (Any Mode)",
                "command": "python train_with_hydra_zen.py --config-path conf --config-name hpc_optimized --training normal --dataset hcrl_sa",
                "description": "Use HPC-optimized settings (mixed precision, batch optimization, etc.)"
            },
            {
                "name": "6Ô∏è‚É£ Multi-GPU Training",
                "command": "torchrun --nproc_per_node=4 train_with_hydra_zen.py --model gat --dataset hcrl_sa",
                "description": "Distributed training across multiple GPUs"
            }
        ]
        
        for cmd_info in commands:
            logger.info(f"{cmd_info['name']}")
            logger.info(f"   üìù {cmd_info['description']}")
            logger.info(f"   üíª {cmd_info['command']}\\n")
            
        logger.info("üéØ KEY BENEFITS OF UNIFIED APPROACH:")
        logger.info("  ‚úÖ Single training script for all modes")
        logger.info("  ‚úÖ Consistent Hydra-Zen configuration system")  
        logger.info("  ‚úÖ Unified HPC optimization settings")
        logger.info("  ‚úÖ Same SLURM script templates")
        logger.info("  ‚úÖ Easier maintenance and debugging")
        
    def run_quick_test(self):
        """Run a quick test of the unified training system."""
        logger.info("üß™ RUNNING QUICK VALIDATION TEST")
        logger.info("="*50)
        
        # Test script existence and help
        logger.info("Testing training script help...")
        import subprocess
        try:
            result = subprocess.run([
                sys.executable, str(self.training_script), "--help"
            ], capture_output=True, text=True, timeout=30)
            
            if result.returncode == 0:
                logger.info("‚úÖ Training script help works")
                
                # Check if fusion mode is in help output
                if "--training {normal,autoencoder,knowledge_distillation,fusion}" in result.stdout:
                    logger.info("‚úÖ Fusion training mode supported")
                else:
                    logger.info("‚ö†Ô∏è  Fusion mode may not be fully integrated")
                    
            else:
                logger.info("‚ùå Training script help failed")
                logger.info(f"Error: {result.stderr}")
                return False
                
        except subprocess.TimeoutExpired:
            logger.info("‚ö†Ô∏è  Training script help timed out")
            return False
        except Exception as e:
            logger.info(f"‚ùå Error testing training script: {e}")
            return False
            
        # Test configuration loading
        logger.info("\\nTesting HPC configuration...")
        hpc_config = self.project_root / "conf" / "hpc_optimized.yaml"
        if hpc_config.exists():
            logger.info("‚úÖ HPC optimized config exists")
            
            # Check if fusion config is included
            with open(hpc_config) as f:
                content = f.read()
                if "fusion_agent_config" in content:
                    logger.info("‚úÖ Fusion configuration integrated in HPC config")
                else:
                    logger.info("‚ö†Ô∏è  Fusion config missing from HPC optimized config")
        else:
            logger.info("‚ùå HPC optimized config missing")
            return False
            
        logger.info("\\nüéâ QUICK TEST COMPLETED SUCCESSFULLY!")
        logger.info("‚úÖ Unified training approach is working properly")
        return True


def main():
    parser = argparse.ArgumentParser(description="Validate unified training approach")
    parser.add_argument("--quick-test", action="store_true", help="Run quick validation test")
    parser.add_argument("--list-commands", action="store_true", help="List all training commands")
    
    args = parser.parse_args()
    
    validator = UnifiedTrainingValidator()
    
    if args.quick_test:
        success = validator.run_quick_test()
        sys.exit(0 if success else 1)
        
    elif args.list_commands:
        validator.list_training_commands()
        
    else:
        # Default: validate unified approach
        success = validator.validate_unified_approach()
        
        if success:
            logger.info("\\nüéâ VALIDATION SUCCESSFUL!")
            logger.info("‚úÖ Unified training approach is properly set up")
            logger.info("üöÄ Ready for HPC training with single script")
        else:
            logger.info("\\n‚ö†Ô∏è  VALIDATION ISSUES FOUND")
            logger.info("‚ùå Some components need attention before HPC deployment")
            
        sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()