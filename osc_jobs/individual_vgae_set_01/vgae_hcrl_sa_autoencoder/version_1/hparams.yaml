model_config:
  type: vgae
  input_dim: 11
  hidden_channels: 64
  latent_dim: 32
  num_layers: 2
  dropout: 0.2
training_config:
  mode: autoencoder
  max_epochs: 1
  batch_size: 32
  learning_rate: 0.0005
  weight_decay: 0.0001
  optimizer:
    name: adam
    lr: 0.001
    weight_decay: 0.0001
    momentum: 0.9
  scheduler:
    use_scheduler: false
    scheduler_type: cosine
    params:
      T_max: 100
  early_stopping_patience: 15
  gradient_clip_val: 1.0
  accumulate_grad_batches: 1
  precision: 32-true
  find_unused_parameters: false
  optimize_batch_size: false
  batch_size_mode: power
  max_batch_size_trials: 10
  run_test: true
  test_every_n_epochs: 5
  save_top_k: 3
  monitor_metric: val_loss
  monitor_mode: min
  log_every_n_steps: 50
  save_hyperparameters: true
  description: Unsupervised autoencoder training on normal samples only
  reconstruction_loss: mse
  use_normal_samples_only: true
model_type: vgae
training_mode: autoencoder
num_ids: 2049
