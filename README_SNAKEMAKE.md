# Snakemake Pipeline for KD-GAT Training

This directory contains a Snakemake-based pipeline system that replaces the custom `can-train` CLI for managing GNN training experiments.

## ğŸ¯ Quick Start

### 1. Install Snakemake
```bash
conda install -c conda-forge snakemake
```

### 2. Setup
```bash
chmod +x profiles/slurm/slurm-status.py
```

### 3. Test
```bash
# Dry run (see what will execute)
snakemake --profile profiles/slurm -n

# Visualize pipeline
snakemake --dag | dot -Tpdf > dag.pdf
```

### 4. Run
```bash
# Train all teacher models
snakemake --profile profiles/slurm all_teachers --jobs 20

# Train everything (teachers + students)
snakemake --profile profiles/slurm --jobs 20
```

## ğŸ“š Documentation

| File | Purpose |
|------|---------|
| [SNAKEMAKE_SUMMARY.md](SNAKEMAKE_SUMMARY.md) | **START HERE** - Overview and key benefits |
| [SNAKEMAKE_QUICKSTART.md](SNAKEMAKE_QUICKSTART.md) | Common commands and examples |
| [SNAKEMAKE_MIGRATION_PLAN.md](SNAKEMAKE_MIGRATION_PLAN.md) | Detailed migration guide |
| [SNAKEMAKE_MIGRATION_TODO.md](SNAKEMAKE_MIGRATION_TODO.md) | Step-by-step checklist |

## ğŸ—‚ï¸ Files Created

```
.
â”œâ”€â”€ Snakefile                               # Main pipeline definition
â”œâ”€â”€ config/
â”‚   â””â”€â”€ snakemake_config.yaml              # Configuration (datasets, SLURM settings)
â”œâ”€â”€ profiles/
â”‚   â””â”€â”€ slurm/
â”‚       â”œâ”€â”€ config.yaml                     # SLURM executor settings
â”‚       â””â”€â”€ slurm-status.py                 # Job status checker
â”œâ”€â”€ envs/
â”‚   â””â”€â”€ gnn-experiments.yaml               # Conda environment
â””â”€â”€ examples/
    â””â”€â”€ train_with_hydra_zen_snakemake_adapter.py  # Example adapter code
```

## ğŸ“ How It Works

### Pipeline Structure

```
Teacher Pipeline (per dataset):
  VGAE (autoencoder) â†’ GAT (curriculum) â†’ DQN (fusion) â†’ Evaluation

Student Pipeline (per dataset):
  (waits for teachers) â†’ VGAE-KD â†’ GAT-KD â†’ DQN-KD â†’ Evaluation
```

### Automatic Features

âœ… **Dependency Resolution**: GAT waits for VGAE, DQN waits for both
âœ… **Parallel Execution**: Different datasets run in parallel
âœ… **Failure Recovery**: Resume from any point automatically
âœ… **Provenance Tracking**: Complete DAG of execution

## âš™ï¸ Configuration

### Add/Remove Datasets

Edit `config/snakemake_config.yaml`:
```yaml
datasets:
  - hcrl_sa
  - hcrl_ch
  - set_01
  - my_new_dataset  # â† Add here
```

### Customize SLURM Resources

Edit `profiles/slurm/config.yaml`:
```yaml
default-resources:
  - slurm_account=PAS3209
  - slurm_partition=gpu
  - runtime=360  # minutes
  - mem_mb=64000
```

Or override per run:
```bash
snakemake --profile profiles/slurm \
    --set-resources train_dqn:mem_mb=128000 \
    --jobs 20
```

## ğŸ”§ Critical Code Change Required

âš ï¸ **You must modify `train_with_hydra_zen.py`** to support simple CLI arguments from Snakemake.

See `examples/train_with_hydra_zen_snakemake_adapter.py` for example code.

### Why?

Snakemake calls your training script like this:
```bash
python train_with_hydra_zen.py \
    --model vgae \
    --model-size teacher \
    --dataset hcrl_sa \
    --output-dir /path/to/output
```

Your current script expects frozen configs from `can-train`. The adapter code lets it support both.

## ğŸ“‹ Common Commands

```bash
# Dry run (see what will execute)
snakemake --profile profiles/slurm -n

# Run specific dataset
snakemake --profile profiles/slurm \
    results/automotive/hcrl_sa/teacher/no_distillation/evaluation/dqn_eval.json

# Resume from failures
snakemake --profile profiles/slurm --rerun-incomplete --jobs 20

# Force rerun specific stage
snakemake --profile profiles/slurm --forcerun train_gat --jobs 20

# Monitor jobs
watch -n 10 'squeue -u $USER'

# Check logs
tail -f experimentruns/automotive/hcrl_sa/vgae/teacher/no_distillation/autoencoder/logs/training.log
```

## ğŸ› Troubleshooting

### Jobs Not Submitting
```bash
# Test SLURM access
sacctmgr show assoc where user=$USER
sinfo -o "%20P %5a %10l %6D"

# Test status script
python profiles/slurm/slurm-status.py <job_id>
```

### Missing Input Files
```bash
# Check what Snakemake expects
snakemake --profile profiles/slurm --summary

# See why a file will be created
snakemake --profile profiles/slurm -n -r <target_file>
```

### Locked Directory
```bash
# If Snakemake was interrupted
snakemake --unlock
```

See [SNAKEMAKE_MIGRATION_PLAN.md](SNAKEMAKE_MIGRATION_PLAN.md#common-issues--solutions) for more.

## ğŸš€ Benefits Over Old System

| Feature | Old (can-train) | New (Snakemake) |
|---------|----------------|-----------------|
| **Lines of code** | 2,000+ | ~400 |
| **Dependency tracking** | Manual job IDs | Automatic (file-based) |
| **Resume from failures** | Manual resubmit | Automatic |
| **Pipeline visualization** | None | Built-in DAG |
| **Parallel execution** | Manual coordination | Automatic |
| **Reproducibility** | Good (frozen configs) | Excellent (DAG + configs) |
| **Community support** | None (custom) | Large Snakemake community |

## ğŸ“Š Example: Run Full Pipeline

```bash
# 1. Dry run to see plan
snakemake --profile profiles/slurm -n

# 2. Visualize dependencies
snakemake --dag | dot -Tpdf > pipeline_dag.pdf

# 3. Run all teachers (6 datasets Ã— 3 models = 18 training jobs + evaluations)
snakemake --profile profiles/slurm all_teachers --jobs 20

# 4. Monitor progress
watch -n 10 'squeue -u $USER'

# 5. Once teachers complete, run students (waits for teachers automatically)
snakemake --profile profiles/slurm all_students --jobs 20

# 6. Generate summary report
snakemake --profile profiles/slurm generate_report
```

## ğŸ—ºï¸ Migration Roadmap

1. **Read** [SNAKEMAKE_SUMMARY.md](SNAKEMAKE_SUMMARY.md) â† Start here
2. **Install** Snakemake and setup profile
3. **Modify** `train_with_hydra_zen.py` (critical!)
4. **Test** with single dataset
5. **Validate** results match old pipeline
6. **Migrate** fully

Estimated time: 1-2 weeks

See [SNAKEMAKE_MIGRATION_TODO.md](SNAKEMAKE_MIGRATION_TODO.md) for detailed checklist.

## ğŸ¤ Getting Help

- **Quick reference**: [SNAKEMAKE_QUICKSTART.md](SNAKEMAKE_QUICKSTART.md)
- **Detailed guide**: [SNAKEMAKE_MIGRATION_PLAN.md](SNAKEMAKE_MIGRATION_PLAN.md)
- **Official docs**: https://snakemake.readthedocs.io/
- **Tutorial**: https://snakemake.readthedocs.io/en/stable/tutorial/tutorial.html

## ğŸ¯ Success Criteria

Migration is complete when:
- âœ… All datasets train via Snakemake
- âœ… Results match old pipeline
- âœ… Dependencies work automatically
- âœ… Failures recover gracefully
- âœ… Team is comfortable with new system

## ğŸ”„ Backward Compatibility

During migration:
- `can-train` CLI still works
- Old shell scripts still functional
- Gradual transition supported

After migration:
- Old scripts moved to `legacy/` directory
- Can keep `can-train` for quick ad-hoc experiments (optional)

## ğŸ“ Next Steps

1. Read [SNAKEMAKE_SUMMARY.md](SNAKEMAKE_SUMMARY.md)
2. Follow [SNAKEMAKE_MIGRATION_TODO.md](SNAKEMAKE_MIGRATION_TODO.md)
3. Test with single dataset
4. Validate and migrate

Good luck! ğŸš€
