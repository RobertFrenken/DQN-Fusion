# ===========================================================================
# KD-GAT Pipeline Orchestration
#
# Path layout (simplified): {EXP}/{ds}/{size}_{stage}[_kd]
#
# Before: 8 levels (modality/dataset/size/learning/arch/distill/mode)
# After:  2 levels (dataset/run_name)
#
# All datasets:
#   snakemake -s pipeline/Snakefile --profile profiles/slurm --jobs 20
#
# Single dataset:
#   snakemake -s pipeline/Snakefile --config datasets='["hcrl_sa"]' -n
#
# Dry run:
#   snakemake -s pipeline/Snakefile -n
#
# DAG:
#   snakemake -s pipeline/Snakefile --dag | dot -Tpdf > dag.pdf
# ===========================================================================

import yaml as _yaml
with open("data/datasets.yaml") as _f:
    ALL_DATASETS = list(_yaml.safe_load(_f).keys())
DATASETS     = config.get("datasets", ALL_DATASETS)
EXP       = "experimentruns"
CLI       = "/users/PAS2022/rf15/.conda/envs/gnn-experiments/bin/python -m pipeline.cli"
PY        = "/users/PAS2022/rf15/.conda/envs/gnn-experiments/bin/python"

# Helper: build canonical checkpoint path (2-level structure)
# {EXP}/{ds}/{size}_{stage}[_kd]/best_model.pt
def _p(ds, size, stage, kd=False):
    suffix = "_kd" if kd else ""
    return f"{EXP}/{ds}/{size}_{stage}{suffix}/best_model.pt"

# Pre-initialize MLflow DB on the login node before any SLURM jobs start.
# Prevents race condition when multiple jobs try to CREATE TABLE concurrently.
onstart:
    shell("{PY} -c 'from pipeline.tracking import setup_tracking; setup_tracking()'")

# After all rules succeed: backup MLflow DB and populate project DB.
onsuccess:
    shell("mkdir -p ~/backups && cp /fs/scratch/PAS1266/kd_gat_mlflow/mlflow.db ~/backups/mlflow_$(date +%Y%m%d).db")
    shell("{PY} -m pipeline.db populate")

# ---------------------------------------------------------------------------
# Targets
# ---------------------------------------------------------------------------

rule all:
    input:
        # Teacher pipeline
        expand(_p("{ds}", "teacher", "fusion"), ds=DATASETS),
        # Student with KD
        expand(_p("{ds}", "student", "fusion", kd=True), ds=DATASETS),
        # Student without KD (ablation)
        expand(_p("{ds}", "student", "fusion"), ds=DATASETS),

rule teachers:
    input:
        expand(_p("{ds}", "teacher", "fusion"), ds=DATASETS),

rule students:
    input:
        expand(_p("{ds}", "student", "fusion", kd=True), ds=DATASETS),

rule students_nokd:
    input:
        expand(_p("{ds}", "student", "fusion"), ds=DATASETS),

rule evaluate_all:
    input:
        expand(EXP + "/{ds}/teacher_evaluation/metrics.json", ds=DATASETS),
        expand(EXP + "/{ds}/student_evaluation_kd/metrics.json", ds=DATASETS),
        expand(EXP + "/{ds}/student_evaluation/metrics.json", ds=DATASETS),

# ---------------------------------------------------------------------------
# SLURM resource defaults
# ---------------------------------------------------------------------------

_TRAIN_RES = dict(
    time_min=360, mem_mb=128000, cpus_per_task=16, gpus=1, gpu_type="v100",
    slurm_account="PAS3209", slurm_partition="gpu",
)
_EVAL_RES = dict(
    time_min=120, mem_mb=32000, cpus_per_task=8, gpus=1, gpu_type="v100",
    slurm_account="PAS3209", slurm_partition="gpu",
)

# ===========================================================================
# Teacher pipeline  (no KD dependencies, runs first)
# ===========================================================================

rule vgae_teacher:
    output:
        _p("{ds}", "teacher", "autoencoder"),
    benchmark:
        EXP + "/{ds}/teacher_autoencoder/benchmark.tsv"
    resources: **_TRAIN_RES,
    log:
        out=EXP + "/{ds}/teacher_autoencoder/slurm.out",
        err=EXP + "/{ds}/teacher_autoencoder/slurm.err",
    shell:
        CLI + " autoencoder --preset vgae,teacher --dataset {wildcards.ds}"
        " > {log.out} 2> {log.err}"

rule gat_teacher:
    input:
        vgae=_p("{ds}", "teacher", "autoencoder"),
    output:
        _p("{ds}", "teacher", "curriculum"),
    benchmark:
        EXP + "/{ds}/teacher_curriculum/benchmark.tsv"
    resources: **_TRAIN_RES,
    log:
        out=EXP + "/{ds}/teacher_curriculum/slurm.out",
        err=EXP + "/{ds}/teacher_curriculum/slurm.err",
    shell:
        CLI + " curriculum --preset gat,teacher --dataset {wildcards.ds}"
        " > {log.out} 2> {log.err}"

rule dqn_teacher:
    input:
        vgae=_p("{ds}", "teacher", "autoencoder"),
        gat=_p("{ds}", "teacher", "curriculum"),
    output:
        _p("{ds}", "teacher", "fusion"),
    benchmark:
        EXP + "/{ds}/teacher_fusion/benchmark.tsv"
    resources: **_TRAIN_RES,
    log:
        out=EXP + "/{ds}/teacher_fusion/slurm.out",
        err=EXP + "/{ds}/teacher_fusion/slurm.err",
    shell:
        CLI + " fusion --preset dqn,teacher --dataset {wildcards.ds}"
        " > {log.out} 2> {log.err}"

# ===========================================================================
# Student with KD  (each stage depends on teacher counterpart)
# ===========================================================================

rule vgae_student:
    input:
        teacher=_p("{ds}", "teacher", "autoencoder"),
    output:
        _p("{ds}", "student", "autoencoder", kd=True),
    benchmark:
        EXP + "/{ds}/student_autoencoder_kd/benchmark.tsv"
    resources: **_TRAIN_RES,
    log:
        out=EXP + "/{ds}/student_autoencoder_kd/slurm.out",
        err=EXP + "/{ds}/student_autoencoder_kd/slurm.err",
    shell:
        CLI + " autoencoder --preset vgae,student --dataset {wildcards.ds}"
        " --teacher-path {input.teacher} --use-kd true"
        " > {log.out} 2> {log.err}"

rule gat_student:
    input:
        teacher=_p("{ds}", "teacher", "curriculum"),
        vgae=_p("{ds}", "student", "autoencoder", kd=True),
    output:
        _p("{ds}", "student", "curriculum", kd=True),
    benchmark:
        EXP + "/{ds}/student_curriculum_kd/benchmark.tsv"
    resources: **_TRAIN_RES,
    log:
        out=EXP + "/{ds}/student_curriculum_kd/slurm.out",
        err=EXP + "/{ds}/student_curriculum_kd/slurm.err",
    shell:
        CLI + " curriculum --preset gat,student --dataset {wildcards.ds}"
        " --teacher-path {input.teacher} --use-kd true"
        " > {log.out} 2> {log.err}"

rule dqn_student:
    input:
        teacher=_p("{ds}", "teacher", "fusion"),
        vgae=_p("{ds}", "student", "autoencoder", kd=True),
        gat=_p("{ds}", "student", "curriculum", kd=True),
    output:
        _p("{ds}", "student", "fusion", kd=True),
    benchmark:
        EXP + "/{ds}/student_fusion_kd/benchmark.tsv"
    resources: **_TRAIN_RES,
    log:
        out=EXP + "/{ds}/student_fusion_kd/slurm.out",
        err=EXP + "/{ds}/student_fusion_kd/slurm.err",
    shell:
        CLI + " fusion --preset dqn,student --dataset {wildcards.ds}"
        " --teacher-path {input.teacher} --use-kd true"
        " > {log.out} 2> {log.err}"

# ===========================================================================
# Student without KD  (ablation â€” no teacher dependency)
# ===========================================================================

rule vgae_student_nokd:
    output:
        _p("{ds}", "student", "autoencoder"),
    benchmark:
        EXP + "/{ds}/student_autoencoder/benchmark.tsv"
    resources: **_TRAIN_RES,
    log:
        out=EXP + "/{ds}/student_autoencoder/slurm.out",
        err=EXP + "/{ds}/student_autoencoder/slurm.err",
    shell:
        CLI + " autoencoder --preset vgae,student --dataset {wildcards.ds}"
        " --use-kd false"
        " > {log.out} 2> {log.err}"

rule gat_student_nokd:
    input:
        vgae=_p("{ds}", "student", "autoencoder"),
    output:
        _p("{ds}", "student", "curriculum"),
    benchmark:
        EXP + "/{ds}/student_curriculum/benchmark.tsv"
    resources: **_TRAIN_RES,
    log:
        out=EXP + "/{ds}/student_curriculum/slurm.out",
        err=EXP + "/{ds}/student_curriculum/slurm.err",
    shell:
        CLI + " curriculum --preset gat,student --dataset {wildcards.ds}"
        " --use-kd false"
        " > {log.out} 2> {log.err}"

rule dqn_student_nokd:
    input:
        vgae=_p("{ds}", "student", "autoencoder"),
        gat=_p("{ds}", "student", "curriculum"),
    output:
        _p("{ds}", "student", "fusion"),
    benchmark:
        EXP + "/{ds}/student_fusion/benchmark.tsv"
    resources: **_TRAIN_RES,
    log:
        out=EXP + "/{ds}/student_fusion/slurm.out",
        err=EXP + "/{ds}/student_fusion/slurm.err",
    shell:
        CLI + " fusion --preset dqn,student --dataset {wildcards.ds}"
        " --use-kd false"
        " > {log.out} 2> {log.err}"

# ===========================================================================
# Evaluation  (one rule per pipeline variant)
# ===========================================================================

rule eval_teacher:
    input:
        vgae=_p("{ds}", "teacher", "autoencoder"),
        gat=_p("{ds}", "teacher", "curriculum"),
        dqn=_p("{ds}", "teacher", "fusion"),
    output:
        report(
            EXP + "/{ds}/teacher_evaluation/metrics.json",
            category="Evaluation",
            caption="Teacher evaluation metrics for dataset {ds}",
        ),
    benchmark:
        EXP + "/{ds}/teacher_evaluation/benchmark.tsv"
    resources: **_EVAL_RES,
    log:
        out=EXP + "/{ds}/teacher_evaluation/slurm.out",
        err=EXP + "/{ds}/teacher_evaluation/slurm.err",
    shell:
        CLI + " evaluation --dataset {wildcards.ds} --model-size teacher"
        " > {log.out} 2> {log.err}"

rule eval_student:
    input:
        vgae=_p("{ds}", "student", "autoencoder", kd=True),
        gat=_p("{ds}", "student", "curriculum", kd=True),
        dqn=_p("{ds}", "student", "fusion", kd=True),
    output:
        report(
            EXP + "/{ds}/student_evaluation_kd/metrics.json",
            category="Evaluation",
            caption="Student+KD evaluation metrics for dataset {ds}",
        ),
    benchmark:
        EXP + "/{ds}/student_evaluation_kd/benchmark.tsv"
    resources: **_EVAL_RES,
    log:
        out=EXP + "/{ds}/student_evaluation_kd/slurm.out",
        err=EXP + "/{ds}/student_evaluation_kd/slurm.err",
    shell:
        CLI + " evaluation --dataset {wildcards.ds} --model-size student --use-kd true"
        " > {log.out} 2> {log.err}"

rule eval_student_nokd:
    input:
        vgae=_p("{ds}", "student", "autoencoder"),
        gat=_p("{ds}", "student", "curriculum"),
        dqn=_p("{ds}", "student", "fusion"),
    output:
        report(
            EXP + "/{ds}/student_evaluation/metrics.json",
            category="Evaluation",
            caption="Student (no KD) evaluation metrics for dataset {ds}",
        ),
    benchmark:
        EXP + "/{ds}/student_evaluation/benchmark.tsv"
    resources: **_EVAL_RES,
    log:
        out=EXP + "/{ds}/student_evaluation/slurm.out",
        err=EXP + "/{ds}/student_evaluation/slurm.err",
    shell:
        CLI + " evaluation --dataset {wildcards.ds} --model-size student"
        " > {log.out} 2> {log.err}"

# ---------------------------------------------------------------------------
# Reports (parameterized notebooks via Papermill)
# ---------------------------------------------------------------------------

rule notebook_report:
    input:
        EXP + "/{ds}/teacher_evaluation/metrics.json",
    output:
        EXP + "/{ds}/report/analysis.ipynb",
    resources:
        time_min=30, mem_mb=8000, cpus_per_task=4, gpus=0,
        slurm_account="PAS3209", slurm_partition="serial",
    shell:
        PY + " -m papermill notebooks/03_analytics.ipynb {output} -p dataset {wildcards.ds}"

# ---------------------------------------------------------------------------
# Utilities
# ---------------------------------------------------------------------------

rule clean_logs:
    shell: "find {EXP} -name 'slurm.*' -delete"

rule clean_all:
    shell: "rm -rf {EXP}"
