# Autoencoder training configuration - only learns from normal samples
mode: autoencoder
type: "unsupervised_autoencoder"
description: "Autoencoder training using only normal samples for anomaly detection"

# Training parameters
max_epochs: 150                 # Autoencoders typically need more epochs
batch_size: 64                  # Larger batches for stable reconstruction
learning_rate: 0.0005           # Lower LR for stable autoencoder training
weight_decay: 0.0001

# Autoencoder specific settings
reconstruction_loss: "mse"      # mse, mae, huber
normal_samples_only: true       # Critical: only use normal samples (label == 0)
reconstruction_threshold: null  # Will be computed from validation set

# Optimization
optimizer: "adam"
use_scheduler: true
scheduler_type: "cosine"
scheduler_params:
  T_max: 150

# Lightning Tuner settings
optimize_batch_size: true
batch_size_mode: "power"
max_batch_size_trials: 25

# Training behavior
early_stopping_patience: 20    # More patience for autoencoder convergence
gradient_clip_val: 1.0
accumulate_grad_batches: 1

# Evaluation
run_test: true
test_every_n_epochs: 15

# Checkpointing
save_top_k: 3
monitor_metric: "val_loss"      # Reconstruction loss
monitor_mode: "min"

# Hardware optimization
precision: "auto"
find_unused_parameters: false

# Logging
log_every_n_steps: 50
save_hyperparameters: true

# Anomaly detection evaluation
anomaly_detection:
  compute_threshold: true       # Compute anomaly threshold from normal samples
  threshold_percentile: 95      # Use 95th percentile of normal reconstruction errors