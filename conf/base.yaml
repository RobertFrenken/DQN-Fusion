---
epochs: 5
lr: 0.0005
train_ratio: 0.8
root_folder: hcrl_sa
batch_size: 512
momentum: 0.9
datasize: 1.0
optimizer: torch.optim.SGD
_target_: trainers.DistillationTrainer
device: cuda
use_focal_loss: true
profile: false

# Enhanced fusion parameters for better learning
fusion_episodes: 1000           # Double episodes for more exposure
max_train_samples: 150000      # 4x increase (adjust per dataset)
max_val_samples: 30000         # 4x increase  
alpha_steps: 21                # More granular actions: 0.0, 0.033, 0.067, ..., 1.0
fusion_lr: 0.015               # Higher LR for faster learning
fusion_epsilon: 0.7            # Higher exploration initially
fusion_epsilon_decay: 0.998    # Slower decay
fusion_min_epsilon: 0.15       # Higher minimum exploration
fusion_buffer_size: 200000     # 20x larger buffer for V100 memory
fusion_batch_size: 512         # 4x larger batches
fusion_target_update: 50       # More frequent target updates
episode_sample_size: 10000     # Process more samples per episode