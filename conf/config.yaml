# Main configuration file - Lightning-optimized structure
# Usage: python train_models.py model=gat dataset=hcrl_sa training=normal

defaults:
  - model: gat                    # model/gat.yaml or model/vgae.yaml
  - dataset: hcrl_sa             # dataset/hcrl_sa.yaml, dataset/set_01.yaml, etc.
  - training: normal             # training/normal.yaml, training/autoencoder.yaml, etc.
  - _self_                       # This file's configs override others

# Global settings
seed: 42
project_name: "can_graph_lightning"
experiment_name: "${model.type}_${dataset.name}_${training.mode}"

# Output directories
output_dir: "outputs"
model_save_dir: "saved_models"
log_dir: "outputs/lightning_logs"

# Lightning Trainer settings
trainer:
  max_epochs: 100
  accelerator: auto              # auto, gpu, cpu, mps
  devices: auto                 # auto, 1, 2, [0,1], etc.
  precision: '32-true'          # '32-true', '16-mixed', 'bf16-mixed'
  gradient_clip_val: 1.0        # Gradient clipping for stability
  log_every_n_steps: 50
  enable_checkpointing: true
  
# Logging and monitoring
logging:
  level: INFO
  enable_tensorboard: false     # Set to true for TensorBoard logging
  save_top_k: 3                # Keep top 3 models
  monitor_metric: "val_loss"    # Metric to monitor for checkpointing
  monitor_mode: "min"           # min for loss, max for accuracy